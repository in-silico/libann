\documentclass{article}

\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{verbatim}
\usepackage{algpseudocode}
\usepackage{natbib}
\usepackage{url}

\begin{document}

\title{Paper currency recognition with color histograms}
\author{Sebastian Gomez \\ Tatiana Lopez}
\maketitle

\begin{abstract}
This document shows an approach to make a color histogram based classification of paper currency from an image.
%todo:Terminar abstract
\end{abstract}

\section{Introduction}
For blind people in many countries it is hard to recognize the denomination of their local paper currency because
there are not enough non optic features in the bills. It would be useful for them to have automated software that
can recognize the currency denomination from an image.

There are several publications on these kinds of systems. %todo: Mention them

Our approach uses only color information, but the accuracy might be improved by adding features that make use of
texture information.

\section{Methodology}

The classification system consist of a feature extraction part, whose responsibility is to compute a vector of
fixed dimensionality. That feature vector is then feeded to a machine learning algorithm to classify the input
into one of the corresponding classes.

\subsection{Feature extraction}

The features used in this system are only color based features. RGB is a color model that expresses the color of
each pixel as a vector in a 3-Dimensional space, whose components represent the intensities of red, green and blue
channels respectively. This model is widely used for screens, cameras and other optical devices but its disadvantage is 
that it mixes color and brightness information. As the idea is to classify bills regardless of the how bright or 
dark is the scene, some degree of brightness invariance in the feature vectore is desirable.

In order to achieve invariance to brightness in the images, a color model created by cielab was used %cite
named Yxy, where the Y channel carries the brightness information while x and y are the chrominance (color) 
channels. To transform RGB to Yxy and viceversa a linear transformation, followed by a normalization are
performed. Brightness invariance is obtained when each pixel in the image is transformed to Yxy and the
Y channel is dropped, this color model is called xy and from it you can not obtain the original image.

One very used technique to extract color information is to generate color histograms. For each pixel
the bin were it falls must be determined, and the final output is the count of how many pixels fall
into each bin. As the color information used is 2-Dimensional (xy model), the ammount of histogram
bins grow quadratically with the number of division used for each dimension. 

For example, suppose that both x and y vary from 0 to 100. And that the bins intervals are each 5
units, so you would have 20 division in each dimension. The bins would look like a 20 by 20 matrix
and the goal is to count how many (x,y) point fall into each slot of the matrix (bin). Note that
it that case there would be $20^2=400$ different bins.

The problem with that approach is that, as the points do not distrubute uniformly, some bins might
never be used at all while some other could end up having most of the points. Instead of choosing the
bins that way, a K-Means algorithm was run over the input points to choose the bins. By doing so
the centroids would not be placed in regions were there are not any points and hopefully in the
regions were there are more points more centers would be placed. To determine the bin were each pixel
falls the closest centroid to that point must be computed using the euclidean distance.

In summary, the feature vectors used for this work were computed as color histograms in the
xy color model space. And the histogram bins were computed using k-means, where k is the
ammount of bins desired for the histogram.

%todo: Append images modifying Yxy brightness

\subsection{Classification system}

\subsubsection{Linear classifier}
The optimization algorithm used to find the weights $\vec{w}$ that minimized the classification error on the training 
set was conjugate gradient.
Since this work is focused in a multiclass classification problem, the functions employed to calculate the output $\vec{y}$, the error $E$
and derivatives of such error with respect to the weights $\nabla E$ were the softmax function (eq. \ref{eq:softmax}), 
the cross-entropy error function (eq. \ref{eq:crossee}), and the error gradient (eq. \ref{eq:gradSoftMax}) respectively.
\begin{align}
E(\vec{w}) &= -\sum_{n=1}^{N}{\sum_{k=1}^{K}{\vec{t}_{n,k} \ln \vec{y}_{k}(\vec{w},\vec{x_{n}})}} \label{eq:crossee} \\
\nabla E(\vec{w}) &=  \sum_{n=1}^{N}{(\vec{y}_{n} - \vec{t}_{n})*\vec{x}_{n}} \label{eq:gradSoftMax}
\end{align}

Where $N$ corresponds to the number of training sets, $\vec{x}$ is the feature vector, $K$ is the number of classes
and $\vec{w}$ is the weight matrix composed of $N$ rows and $K$ columns, giving K discriminant functions one for
each class. The known output of the training set $\vec{t}$ is also a matrix of $N * K$ dimensions, where for each row, 
there is only a value of 1 at a column k, indicating that such training row belongs to class k.

\subsubsection{Multilayer perceptron}
The multilayer perceptrons used in this project used a sigmoid function (eq. \ref{eq:sigmoid}) as the
activation function for the hidden layers and a softmax function (eq. \ref{eq:softmax}) for the output layer
because the task of classification is for multiple classes.

\begin{align}
\sigma(x) &= \frac{1}{1+e^{-x}} \label{eq:sigmoid} \\ 
S_j(\vec{x}) &= \frac{e^{x_j}}{\sum_{i=1}^D{e^{x_i}}} \label{eq:softmax}
\end{align}

The network was trained using back propagation algorithm to compute the gradients and the complex conjugate
optimization algorithm was used to find the weights that decrease the network error on the training set on
each iteration. Let $W_{ij}$ be the weight of the input value $j$ to the hidden neuron $i$, and $V_{ij}$ be
the weight of the hidden neuron output $j$ to the output neuron $i$. Then the gradients are computed as:

\begin{align}
\Delta V_{ij} &= \sum_{t=1}^{N}{ \sum_{i=1}^{K}{ \sum_{h=1}^{H+1}{(Y_{ti} - R_{ti}) \hat{Z}_{th}} } } \label{eq:gradV} \\ 
\Delta W_{ij} &= \sum_{t=1}^{N}{ \sum_{h=1}^{H}{ \sum_{j=1}^{D+1}{
    \left[ Z_{th}(1 - Z_{th})\hat{X}_{tj} \sum_{i=1}^{K}{ (Y_{ti} - R_{ti})V_{i(h+1)} } \right]
} } } \label{eq:gradW}
\end{align}

Where $N$ is the number of training instances, $K$ the number of classes, $H$ the number of hidden neurons 
and $D$ the number of input dimensions. A hat over a matrix denotes the matrix extended with a column of
ones (for the bias terms) appended at the beginning of the matrix. The matrices $X$,$Y$,$R$ and $Z$ are
the input data, output data, correct result and output of the hidden layer respectively.

\subsection{Data analysis}

%PCA plot analysis
\subsubsection{Principal components analysis}
In order to visualize the data in 2D, the PCA dimensionality reduction algorithm was performed.
The goal of this algorithm is to find a lower dimensional space into which project the data, minimizing
the average orthogonal distances of the feature vector $\vec{x}$ into the projection space. First, the data
was normalized, and the covariance matrix $\Sigma$ was found. Then, this covariance matrix was used to find the
first two eigenvectors onto wich project the data. The percentage of variace retained by the projection 
(eq. \ref{eq:svderr}) was calculated with the matrix $S$ given by the octave $[U,S,V] = svd(\Sigma)$ function as:

\begin{align}
\frac{\sum_{i=1}^{k}S_{ii}}{\sum_{i=1}^{m}S_{ii}} \label{eq:svderr}
\end{align}

Where k is the dimension of the projection space (in this case 2), and m is the dimension of the original space.

%Explain precision/recall
\subsubsection{Measuring performance}

\section{Results}

The first test was to determine a good number of hidden neurons and iterations that could generalize well
on a validation set. For this test the training algorithm was run 5 times for each parameter pair of number
of hidden neurons and number of iterations $<i,h>$ where $i \in \{{600,1000\}$

%table of errors on training and validation

%table of correct/predicted counts

%precision and recall measures

\section{Conclusions}

\end{document}
